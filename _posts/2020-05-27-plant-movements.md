---
layout: post
title: "Plant Movement [Under Construction]"
author: "Sebastian"
categories: project
---

# Attention: This is a construction site.

## Tracking Plants - Basic Infrastructure

Please find my basic training infrastructure that allows us to track the motion of plants via machine learning algorithms.
<iframe width="100%" height="400" src="https://www.youtube.com/embed/xgAhZQMkE7U?start=2" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Hosted in a Jupyter notebook on Google Colab
Try it: [Tracking Plants Colab](https://github.com/plantions/video-edge-extractor/).

### Fine-Tuning Hyperparameters

The Jupyter notebook is designed so that hyper parameters are cumulated and can be trained to fine-tune for the peculiarities of leaf tracking for carnivore plants. ![Hyperparameters](https://i.imgur.com/uU0mCnt.png)

### From Test Files to Comprehensive Dataset

Use the new videos recently created by Prof. Gloor, and benefit from the computing power of your Google Colaboratory Jupyter notebook. (Done)

### Get X, Y-Values for further Plant Analysis
These values are saved in the list leafs.(Done)

### Hyper-Parameter Cross-Tests

- Make sliders to set parameters. (Done)
- Set up cross-validation tables. (in progress)

### Correlate with Underlying Audio Files to Identify Leaf Reactions (tbd)
- Extract the MFCC of the accompanying audio sounds together with sounds to start correlation analysis.

### Make it clean
- Refactor code
- Try different settings
- Write down all the experiments
- Go for extreme Values
- Consider cutting videos due to frames for different Plants
- Make annotations which plant has which sound in the background
